{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0602efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7362a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in folder angry\n",
      "Loading in folder disgust\n",
      "Loading in folder fear\n",
      "Loading in folder happy\n",
      "Loading in folder neutral\n",
      "Loading in folder sad\n",
      "Loading in folder surprise\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "    image = image/255\n",
    "    return image\n",
    "\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "for i in [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]:\n",
    "    collectionImageNames = os.listdir(\"D:/another data\" + \"/\" + str(i))\n",
    "    for j in collectionImageNames:\n",
    "        img = cv2.imread(\"D:/another data\" + \"/\" + str(i) + \"/\" + j)\n",
    "        features.append(img)\n",
    "        if i == \"angry\":\n",
    "            targets.append(0)\n",
    "        elif i == \"disgust\":\n",
    "            targets.append(1)\n",
    "        elif i == \"fear\":\n",
    "            targets.append(2)\n",
    "        elif i == \"happy\":\n",
    "            targets.append(3)\n",
    "        elif i == \"neutral\":\n",
    "            targets.append(4)\n",
    "        elif i == \"sad\":\n",
    "            targets.append(5)\n",
    "        elif i == \"surprise\":\n",
    "            targets.append(6)\n",
    "    print(\"Loading in folder\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d840826",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "targets = np.array(targets)\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, targets, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e0b52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821, 48, 48, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d2dc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cd2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(list(map(preprocessing, train_features)))\n",
    "test_features = np.array(list(map(preprocessing, test_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a415327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23056, 48, 48)\n",
      "(5765, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a260bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(23056, 48, 48, 1)\n",
    "test_features = test_features.reshape(5765, 48, 48, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65bfb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23056, 48, 48, 1)\n",
      "(5765, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d44d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                             shear_range=0.1, zoom_range=0.2)\n",
    "DataGen.fit(train_features)\n",
    "batches = DataGen.flow(train_features, train_target, batch_size=20)\n",
    "train_target = to_categorical(train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3cafeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1------ Specify the architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(60, (3, 3), activation=\"relu\", input_shape=(48, 48, 1)))\n",
    "model.add(Conv2D(60, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(30, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(30, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(30, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation=\"relu\"))\n",
    "model.add(Dense(200, activation=\"relu\"))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0771de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 46, 46, 60)        600       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 44, 44, 60)        32460     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 20, 20, 30)        16230     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 30)        8130      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 30)        8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 30)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               384200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 1407      \n",
      "=================================================================\n",
      "Total params: 491,357\n",
      "Trainable params: 491,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2735cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2----- Compile the model\n",
    "model.compile(Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ea3c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1153/1153 [==============================] - 78s 67ms/step - loss: 1.8233 - accuracy: 0.2475\n",
      "Epoch 2/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.7422 - accuracy: 0.2826\n",
      "Epoch 3/20\n",
      "1153/1153 [==============================] - 73s 63ms/step - loss: 1.6858 - accuracy: 0.3257\n",
      "Epoch 4/20\n",
      "1153/1153 [==============================] - 73s 63ms/step - loss: 1.6059 - accuracy: 0.3653\n",
      "Epoch 5/20\n",
      "1153/1153 [==============================] - 73s 63ms/step - loss: 1.5560 - accuracy: 0.3919\n",
      "Epoch 6/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.5133 - accuracy: 0.4104\n",
      "Epoch 7/20\n",
      "1153/1153 [==============================] - 73s 63ms/step - loss: 1.4968 - accuracy: 0.4167\n",
      "Epoch 8/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.4656 - accuracy: 0.4361\n",
      "Epoch 9/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.4524 - accuracy: 0.4356\n",
      "Epoch 10/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.4309 - accuracy: 0.4501\n",
      "Epoch 11/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.3988 - accuracy: 0.4558\n",
      "Epoch 12/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.4005 - accuracy: 0.4574\n",
      "Epoch 13/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.3867 - accuracy: 0.4577\n",
      "Epoch 14/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.3700 - accuracy: 0.4760\n",
      "Epoch 15/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.3645 - accuracy: 0.4733\n",
      "Epoch 16/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.3439 - accuracy: 0.4827\n",
      "Epoch 17/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.3391 - accuracy: 0.4855\n",
      "Epoch 18/20\n",
      "1153/1153 [==============================] - 74s 64ms/step - loss: 1.3368 - accuracy: 0.4872\n",
      "Epoch 19/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.3313 - accuracy: 0.4834\n",
      "Epoch 20/20\n",
      "1153/1153 [==============================] - 73s 64ms/step - loss: 1.3243 - accuracy: 0.4923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2092f09f100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3-----Train the model\n",
    "model.fit(DataGen.flow(train_features, train_target, batch_size=20), epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e0d0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model architecture in the json file\n",
    "Model_In_Json = model.to_json()\n",
    "abc = open(\"emotion_detection_model.json\", \"w\")\n",
    "abc.write(Model_In_Json)\n",
    "abc.close()\n",
    "# saving the model weights in the h5 file\n",
    "model.save_weights(\"emotion_detection_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da1dc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading(loading..) the json file to use it in the model\n",
    "abc = open(\"emotion_detection_model.json\", \"r\")\n",
    "loaded_data = abc.read()\n",
    "loaded_model = model_from_json(loaded_data)\n",
    "loaded_model.load_weights(\"emotion_detection_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f7339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d16fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4------Test the model for the predictions\n",
    "for i in range(10):\n",
    "    predictions = loaded_model.predict(test_features)\n",
    "    print(predictions[i])\n",
    "    print(np.max(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e38983",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36e903d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src data type = 17 is not supported\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-5a6325ed901b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mimage_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mimage_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mimage_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mimage_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src data type = 17 is not supported\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "def getclassname(classno):\n",
    "    if classno == 0:\n",
    "        return \"angry\"\n",
    "    elif classno == 1:\n",
    "        return \"disgust\"\n",
    "    elif classno == 2:\n",
    "        return \"fear\"\n",
    "    elif classno == 3:\n",
    "        return \"happy\"\n",
    "    elif classno == 4:\n",
    "        return \"neutral\"\n",
    "    elif classno == 5:\n",
    "        return \"sad\"\n",
    "    elif classno == 6:\n",
    "        return \"surprise\"\n",
    "\n",
    "\n",
    "def preprocessing(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = image/255\n",
    "    return image\n",
    "\n",
    "\n",
    "abc = open(\"emotion_detection_model.json\", \"r\")\n",
    "loaded_data = abc.read()\n",
    "loaded_model = model_from_json(loaded_data)\n",
    "loaded_model.load_weights(\"emotion_detection_weights.h5\")\n",
    "\n",
    "capt = cv2.VideoCapture(0)\n",
    "capt.set(3, 640)\n",
    "capt.set(4, 480)\n",
    "capt.set(10, 180)\n",
    "while True:\n",
    "    message, image = capt.read()\n",
    "    image_arr = np.asarray(image)\n",
    "    image_arr = cv2.resize(image_arr, (48, 48))\n",
    "    image_arr = preprocessing(image_arr)\n",
    "    image_arr = image_arr.reshape(1, 48, 48, 1)\n",
    "    predictions = loaded_model.predict(image_arr)\n",
    "    Neuron_index = loaded_model.predict(image_arr)\n",
    "    cv2.putText(image, \"Class: \", (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(image, \"Probability: \", (20, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    probability_value = np.amax(predictions)\n",
    "    if probability_value > 0.50:\n",
    "        cv2.putText(image, getclassname(Neuron_index), (120, 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(image, str(int(probability_value*100)) + \"%\", (200, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Model Prediction\", image)\n",
    "    ascii_value = cv2.waitKey(1)\n",
    "    if ascii_value == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d803fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Neuron_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e0d0f299725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuron_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Neuron_index' is not defined"
     ]
    }
   ],
   "source": [
    "print(Neuron_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370e997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e6202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4139db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd020f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763a423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cc79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570a674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ef85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209641e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
